{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRegressResults(regress, parameters, data):\n",
    "\n",
    "  # PREPROCESSING\n",
    "  # Target\n",
    "  y = data['averageRating'].dropna()\n",
    "\n",
    "  # Features preprocessing\n",
    "  X = data.drop(columns='averageRating')\n",
    "  transfo_cat = Pipeline(steps=[\n",
    "        ('imputation', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore')),\n",
    "        ('reduction', TruncatedSVD())\n",
    "  ])\n",
    "\n",
    "  transfo_num = Pipeline(steps=[\n",
    "      ('imputation', SimpleImputer(strategy='median')),\n",
    "      ('scaling', RobustScaler())\n",
    "  ])\n",
    "\n",
    "  preparation = ColumnTransformer(\n",
    "      transformers=[\n",
    "          ('data_cat', transfo_cat , X.select_dtypes(include=['object']).columns),\n",
    "          ('data_num', transfo_num , X.select_dtypes(exclude=['object']).columns)\n",
    "      ])\n",
    "\n",
    "  # train-test-split\t\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2, stratify=y)\t\n",
    "\n",
    "  # Pipeline and Model\n",
    "  model = Pipeline(steps=[('preparation', preparation),\n",
    "                          ('model', regress)])\n",
    "\n",
    "  # Gridsearch\n",
    "  grid = GridSearchCV(estimator = model, param_grid = parameters, scoring = 'r2', cv = 5, n_jobs =-1, verbose = 0)\n",
    "  #grid = GridSearchCV(estimator = model, param_grid = parameters, scoring = 'r2', cv = 5, n_jobs =-1, verbose = 0)\n",
    "\n",
    "  # Fit\n",
    "  grid.fit(X_train, y_train)\n",
    "\n",
    "  # Predict\n",
    "  y_pred = grid.predict(X_test)\n",
    "  test_score = metrics.r2_score(y_test, y_pred)\n",
    "\n",
    "  # Results\n",
    "  regress_results = []\n",
    "  regress_results.append(grid.cv_results_['mean_fit_time'].mean().round(4))\n",
    "  regress_results.append(grid.best_score_.round(4))\n",
    "  regress_results.append(test_score.round(4))\n",
    "  regress_results.append(grid.best_params_)\n",
    "\n",
    "  return(regress_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 900040 entries, 0 to 900039\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   tconst          900040 non-null  object \n",
      " 1   genres          862127 non-null  object \n",
      " 2   runtimeMinutes  786137 non-null  float64\n",
      " 3   averageRating   900040 non-null  float64\n",
      " 4   director_name   900040 non-null  object \n",
      " 5   actor_name      900040 non-null  object \n",
      " 6   actress_name    900040 non-null  object \n",
      "dtypes: float64(2), object(5)\n",
      "memory usage: 54.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data_regression.csv', index_col=0)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         9.0\n",
       "1         9.0\n",
       "2         9.0\n",
       "3         9.0\n",
       "4         9.0\n",
       "         ... \n",
       "900035    4.8\n",
       "900036    4.8\n",
       "900037    6.1\n",
       "900038    6.1\n",
       "900039    6.1\n",
       "Name: averageRating, Length: 900040, dtype: float64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['averageRating']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('averageRating',axis=1).drop('tconst', axis=1)\n",
    "X_num = X.select_dtypes([float])\n",
    "X_cat = X.select_dtypes([object])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alpha',\n",
       " 'average',\n",
       " 'early_stopping',\n",
       " 'epsilon',\n",
       " 'eta0',\n",
       " 'fit_intercept',\n",
       " 'l1_ratio',\n",
       " 'learning_rate',\n",
       " 'loss',\n",
       " 'max_iter',\n",
       " 'n_iter_no_change',\n",
       " 'penalty',\n",
       " 'power_t',\n",
       " 'random_state',\n",
       " 'shuffle',\n",
       " 'tol',\n",
       " 'validation_fraction',\n",
       " 'verbose',\n",
       " 'warm_start']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(SGDRegressor().get_params().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGDRegressor()\n",
    "parameters = {\n",
    "    \"model__loss\": ['huber']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accuracy',\n",
       " 'adjusted_mutual_info_score',\n",
       " 'adjusted_rand_score',\n",
       " 'average_precision',\n",
       " 'balanced_accuracy',\n",
       " 'completeness_score',\n",
       " 'explained_variance',\n",
       " 'f1',\n",
       " 'f1_macro',\n",
       " 'f1_micro',\n",
       " 'f1_samples',\n",
       " 'f1_weighted',\n",
       " 'fowlkes_mallows_score',\n",
       " 'homogeneity_score',\n",
       " 'jaccard',\n",
       " 'jaccard_macro',\n",
       " 'jaccard_micro',\n",
       " 'jaccard_samples',\n",
       " 'jaccard_weighted',\n",
       " 'matthews_corrcoef',\n",
       " 'max_error',\n",
       " 'mutual_info_score',\n",
       " 'neg_brier_score',\n",
       " 'neg_log_loss',\n",
       " 'neg_mean_absolute_error',\n",
       " 'neg_mean_absolute_percentage_error',\n",
       " 'neg_mean_gamma_deviance',\n",
       " 'neg_mean_poisson_deviance',\n",
       " 'neg_mean_squared_error',\n",
       " 'neg_mean_squared_log_error',\n",
       " 'neg_median_absolute_error',\n",
       " 'neg_negative_likelihood_ratio',\n",
       " 'neg_root_mean_squared_error',\n",
       " 'normalized_mutual_info_score',\n",
       " 'positive_likelihood_ratio',\n",
       " 'precision',\n",
       " 'precision_macro',\n",
       " 'precision_micro',\n",
       " 'precision_samples',\n",
       " 'precision_weighted',\n",
       " 'r2',\n",
       " 'rand_score',\n",
       " 'recall',\n",
       " 'recall_macro',\n",
       " 'recall_micro',\n",
       " 'recall_samples',\n",
       " 'recall_weighted',\n",
       " 'roc_auc',\n",
       " 'roc_auc_ovo',\n",
       " 'roc_auc_ovo_weighted',\n",
       " 'roc_auc_ovr',\n",
       " 'roc_auc_ovr_weighted',\n",
       " 'top_k_accuracy',\n",
       " 'v_measure_score']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.get_scorer_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15.2331, -0.0908, 0.0322, {'model__loss': 'huber'}]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getRegressResults(sgd, parameters, data=df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Netfloox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "150f8bce8a0ed1f6707cea83ffc3775a25deaf29f2e3120fc9d158fd4b5e952f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
